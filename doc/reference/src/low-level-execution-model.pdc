## Overview

Juvix translates the semantics of a term to equivalent semantics for an interaction system, consisting of node types, rewrite
rules, write-forward and read-back algorithms (for translating terms to and from nets, respectively),
where elementary-affine-typed terms are in the general case reduced using the oracle-free variant
of Lamping's optimal reduction algorithm.

Compared with previous interaction net interpreters for the lambda calculus utilising a static set
of node types and fixed rewrite rules, Juvix adds an additional degree of freedom:
the node types and rewrite rules of the interaction system can be generated at compile time and even
dynamically altered at runtime according to patterns of rewrite combinations and desired time-space complexity trade-offs.
Additional type data from the core language, such as exact variable usage counts provided by
the instantiation of quantitative type theory with the natural ring, are available to the interaction
system construction algorithm.

also
- refl (equality) proofs in core language can be used by compiler, e.g. with total supply of a token = constant, for queries on the total supply the constant can be returned; more generally if two expressions are equal the compiler can choose which one to evaluate
- will be more effective if graph representation is persistent, instead of written / read-back each contract call. can be used for both code & data

- Define encoding $\phi (t)$ of term $t$ mapping to net $n$
- Define read-back function $\phi ^{-1}(n)$ mapping net $n$ to a term $t$, where $\phi^{-1}(\phi(t)) = t$ holds
- Define interaction system reduction function $\psi(n)$ mapping nets to nets, where $\phi^{-1}(\psi(\phi(t))) = reduce\ t$ where $reduce$ is as defined in the semantics of Juvix Core

## Interaction system encoding

EAL term language $t ::= x\ |\ λx.t\ |\ (t u)\ |\ !t$.

EAL type $A ::= α\ |\ A\ ⊸\ A\ |\ !A$.

EAL-typed terms can be translated into interaction nets, in accordance with the sequent calculus typing rules, as the function $\phi$ as follows.

The EAL term is first erased to a simply-typed term, with EAL types and levels of subterms retained in a lookup table for reference during the translation.

**Abstraction** is applied to terms of the form $λx.t$ and type $A ⊸ B$.

\begin{tikzpicture}
\inetbigcell[right = 30pt]{g}{$\phi (t)$}[4]
\inetbigcell[below = 30pt]{l}{$λ$}[3]

\axWire{g/1}{l/1}{$(arg)$}{}
\cutWire{g.out}{l/2}{}{}
\outwire[]{l.out}{$A ⊸ B$}
\end{tikzpicture}

Wiring of the argument $x$ varies depending on variable usage linearity:

**Weakening**: If $x$ does not appear in the body $t$, the $λ$ argument port is connected to an eraser.

\begin{tikzpicture}
\inetbigcell[right = 30pt]{g}{$\phi (t)$}[4]
\inode[]{e}{$⊗$}
\inetbigcell[below = 30pt]{l}{$λ$}[3]

\cutWire{e}{l/1}{$$}{}
\cutWire{g.out}{l/2}{$$}{}
\outwire[]{l.out}{$A ⊸ B$}
\end{tikzpicture}

**Linear / contraction**: If *x* appears once or more in the body $t$, the $λ$ argument port is connected to the occurrence(s). If there is more than one occurrence, usages will be shared by a set of fan nodes constructed by the application encoding.

\begin{tikzpicture}
\inetbigcell[right = 30pt]{g}{$\phi (t)$}[4]
\inetbigcell[below = 30pt]{l}{$λ$}[3]

\axWire{g/1}{l/1}{}{}
\cutWire{g.out}{l/2}{}{}
\outwire[]{l.out}{$A ⊸ B$}
\end{tikzpicture}

**Application** is applied to terms of the form $(t_1 t_2)$ and type $C$.

\begin{tikzpicture}

\inetbigcell[right = -25 pt]{g}{$\phi(t_1)$}[3]
\inetbigcell[right = 25 pt]{h}{$\phi(t_2)$}[3]
\inetbigcell[below = 40 pt]{a}{$@$}[3]

\cutWire{g.out}{a/1}{}{}
\cutWire{h.out}{a/2}{}{}
\outwire[]{a.out}{$C$}

\end{tikzpicture}

For each free variable $x$ in $(t_1 t_2)$ occurring more than once, all occurrences of $x$ must be connected by a tree of fan-in nodes, each with a globally unique label (only one fan-in node is shown in the diagram).

\begin{tikzpicture}

\inetbigcell[rotate = 180, above = 40 pt]{f}{\rotatebox[origin=c]{180}{$f_i$}}[3]
\inetbigcell[right = -25 pt]{g}{$\phi(t_1)$}[3]
\inetbigcell[right = 25 pt]{h}{$\phi(t_2)$}[3]
\inetbigcell[below = 40 pt]{a}{$@$}[3]

\cutWire{g.out}{a/1}{}{}
\cutWire{h.out}{a/2}{}{}
\outwire[]{a.out}{$C$}
\inwire[]{f.out}{$x$}

\axWire{g/1}{f/1}{}{}
\axWire{h/1}{f/2}{}{}
\end{tikzpicture}

That ends the encoding rules for basic lambda terms.

Interaction net encoding of $a \& b$:

1. Primary port as pair, to be connected to destructor ($fst$ / $snd$)
1. $3n + 2$ auxiliary ports where:
    1. Two are for the subterms $a$ and $b$
    1. $n$ are for the terms bound to free variables (resources) both subterms use
    1. $n$ are connected to the binding sites in a
    1. $n$ are connected to the binding sites in b
1. Rewrite rule
    1. If the destructor is $fst$ (vice versa if the destructor is $snd$):
        1. Connects the wires between the $n$ free variables and the $n$ binding sites in $a$
        1. Attaches erasers to the $n$ binding sites in $b$ and to $b$ itself
        1. Erases $\&$ node
        1. Attaches whatever destructor was connected to to $a$

That way no duplication of resources need occur, matching the linear logic semantics.

Note that this means reduction within $a$ and $b$, insofar as it depends on the values of the free variables, will not take place until the caller chooses which variant ($a$ or $b$) they want.

Interaction net encoding of $a ⊗ b$:

1. Primary port as pair, to be connected to destructor ("join")
1. $2$ auxiliary ports, where:
    1. Two are for the subterms $a$ and $b$
1. Rewrite rule
    1. Erases the ⊗ node
    1. Creates a new ⊗ node, attaches its 2 auxiliary ports to a and b
    1. Attaches whatever the destructor was attached to to the new ⊗ node's primary port

This is structurally identical to the ⊗ encoding (perhaps we can simply erase the "join" destructor prior to runtime), but we should be able to place directives that inform the evaluator to evaluate the two subterms in parallel, as they are guaranteed not to share resources (no duplication required) and be completely disjoint subgraphs.

> TODO: Example term encoding.

### Bespoke function encoding

#### Basics

Consider a Core term $f$ of type $A ⊸ B$.

In the interaction net encoding compiler path, assuming EAL-typeability, we would encode this (if of form $λx.t$, for example) as:

\begin{tikzpicture}
\inetbigcell[right = 30pt]{g}{$\phi (t)$}[4]
\inetbigcell[below = 30pt]{l}{$λ$}[3]

\axWire{g/1}{l/1}{}{}
\cutWire{g.out}{l/2}{}{}
\outwire[]{l.out}{$A ⊸ B$}
\end{tikzpicture}

where $φ$ is the recursive interaction net translation function.

In the bespoke encoding path, we instead create a new node type $T$ and rewrite rule $R$ such that when the primary port of $T$ is connected to an application node to an argument $A$, we erase $T$, connect an eraser to $A$, and connect whatever the application node's primary port was connected to to a new subgraph which is equal to the encoding of $eval (f A)$.

$eval (f A)$ can then be implemented by native evaluation semantics which do not utilise interaction nets. For example, if the Core term in question is a tail-recursive numerical computation, it can be compiled to a native loop (possibly using SIMD).

Furthermore, we can safely encode non-EAL-typable terms this way, such as the Ackermann function, and they can safely interact with the rest of the interaction net (which must have been an EAL-typable term, treating the bespoke-encoded subterm as opaque).

The decision of whether or not to take the bespoke path can be made for all subterms of this form according to some heuristic (or possibly exact cost calculation) in the compiler.

#### Dealing with various types

Where $A$ and $B$ are both types which are encoded as primitive nodes (e.g. integers), this is trivial.

Where $A$ is a primitive type and $B$ is a function of some arity, of only primitive-typed arguments, which then returns a primitive type, this can be implemented as a sequence of node types $T, T', T''$, etc. which keep the curried arguments and eventually evaluate when all arguments are provided (or even when some are provided, there is a continuum of options here).

Where $A$ and/or arguments of $B$ are non-primitive types (e.g. functions), this becomes more complex, since we must convert between AST and interaction-net form during reduction.

More generally, with our Core term $f$ of type $A ⊸ B$, encoding $f$ through the bespoke path would result in a set of new node types $T_i$ with possible curried internal data, and a set of rewrite rules $R_i$, the first $i - 1$ of which just deal with currying (although again, there is a continuum of options, but let's leave that out for now), and the last one of which is interesting, let it be $R$.

$R$ must then cause, when connected to a primary port of an argument $A$:

- Erasure of $R_i$ (the prior node).
- Connection of an eraser to $A$.
- Creation of a new subgraph $φ (eval (f (read-back A))$, where $φ$ is the recursive interaction net encoding function (which might itself perform bespoke encoding, although we need to be concerned about runtime costs here), and $read-back$ is the read-back function from nets to Core terms, run starting at $A$ as the root node.
- Connection of the primary port of this subgraph to whatever $R_i$ was previously connected to.

This follows all the interaction net laws and should preserve semantics - but there are oddities:

- Read-back and (complex) encoding algorithms must be executed at runtime
- Read-back must happen over a term A which may be in the progress of parallel reduction

In general, we have no idea of the size (and corresponding read-back cost) of $A$, and it might be dependent on the order of reduction.

### Bespoke datatype encoding

- Primitive types (integer, string, bytes) ~> node types w/data
- User-defined ADTs can be turned into custom nodes

## Oracle-free optimal reduction

The oracle-free abstract algorithm for optimal reduction operates on four node types: $λ$ (lambda), $@$ (application), $f_i$ (fan, with index $i$), and $⊗$ (eraser). Rewrite rules always operate only on primary port pairs and consist of two categories: **annihilation** rules, which remove nodes, and **commutation** rules, which create nodes.

\floatstyle{plain}
\restylefloat{figure}

\begin{figure}[H]
\caption{Lambda-application annihilation (beta reduction)}
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inetcell[]{a}{$@$}[5]
\inetcell[rotate = 180, below = 50 pt]{l}{\rotatebox[origin=c]{180}{$λ$}}[5]
\inwire[]{a/1}{a}
\inwire[]{a/4}{d}
\outwire[]{l/1}{c}
\outwire[]{l/4}{b}
\cutWire{a.out}{l.out}{}{}
\end{tikzpicture}
\end{subfigure}
~
\begin{subfigure}[c]{0.05\textwidth}
\huge{→}
\end{subfigure}
~
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\wirecross[]{a}{c}{b}{d}
\end{tikzpicture}
\end{subfigure}
\end{figure}

\begin{figure}[H]
\caption{Fan-fan commutation}
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inetcell[]{a}{$f_i$}[5]
\inetcell[rotate = 180, below = 50 pt]{b}{\rotatebox[origin=c]{180}{$f_j$}}[5]
\inwire[]{a/1}{a}
\inwire[]{a/4}{d}
\outwire[]{b/1}{c}
\outwire[]{b/4}{b}
\cutWire{a.out}{b.out}{}{}
\end{tikzpicture}
\end{subfigure}
~
\begin{subfigure}[c]{0.05\textwidth}
\huge{→}
\end{subfigure}
~
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inetcell[rotate = 180]{a}{\rotatebox[origin=c]{180}{$f_j$}}[5]
\inetcell[rotate = 180, right = 60 pt of a]{b}{\rotatebox[origin=c]{180}{$f_j$}}[5]
\inetcell[below = 40 pt of a]{c}{$f_i$}[5]
\inetcell[below = 40 pt of b]{d}{$f_i$}[5]
\inwire[]{a.out}{a}
\inwire[]{b.out}{d}
\outwire[]{c.out}{b}
\outwire[]{d.out}{c}
\swire[0]{a/4}{c/1}{}{}
\swire[0]{b/1}{d/4}{}{}
\swire[0]{a/1}{d/1}{}{}
\swire[0]{b/4}{c/4}{}{}
\end{tikzpicture}
\end{subfigure}
\end{figure}

\begin{figure}[H]
\caption{Fan-application commutation}
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inetcell[]{a}{$f_i$}[5]
\inetcell[rotate = 180, below = 50 pt]{b}{\rotatebox[origin=c]{180}{$@$}}[5]
\inwire[]{a/1}{a}
\inwire[]{a/4}{d}
\outwire[]{b/1}{c}
\outwire[]{b/4}{b}
\cutWire{a.out}{b.out}{}{}
\end{tikzpicture}
\end{subfigure}
~
\begin{subfigure}[c]{0.05\textwidth}
\huge{→}
\end{subfigure}
~
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inetcell[rotate = 180]{a}{\rotatebox[origin=c]{180}{$@$}}[5]
\inetcell[rotate = 180, right = 60 pt of a]{b}{\rotatebox[origin=c]{180}{$@$}}[5]
\inetcell[below = 40 pt of a]{c}{$f_i$}[5]
\inetcell[below = 40 pt of b]{d}{$f_i$}[5]
\inwire[]{a.out}{a}
\inwire[]{b.out}{d}
\outwire[]{c.out}{b}
\outwire[]{d.out}{c}
\swire[0]{a/4}{c/1}{}{}
\swire[0]{b/1}{d/4}{}{}
\swire[0]{a/1}{d/1}{}{}
\swire[0]{b/4}{c/4}{}{}
\end{tikzpicture}
\end{subfigure}
\end{figure}

\begin{figure}[H]
\caption{Fan-lambda commutation}
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inetcell[]{a}{$f_i$}[5]
\inetcell[rotate = 180, below = 50 pt]{b}{\rotatebox[origin=c]{180}{$λ$}}[5]
\inwire[]{a/1}{a}
\inwire[]{a/4}{d}
\outwire[]{b/1}{c}
\outwire[]{b/4}{b}
\cutWire{a.out}{b.out}{}{}
\end{tikzpicture}
\end{subfigure}
~
\begin{subfigure}[c]{0.05\textwidth}
\huge{→}
\end{subfigure}
~
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inetcell[rotate = 180]{a}{\rotatebox[origin=c]{180}{$λ$}}[5]
\inetcell[rotate = 180, right = 60 pt of a]{b}{\rotatebox[origin=c]{180}{$λ$}}[5]
\inetcell[below = 40 pt of a]{c}{$f_i$}[5]
\inetcell[below = 40 pt of b]{d}{$f_i$}[5]
\inwire[]{a.out}{a}
\inwire[]{b.out}{d}
\outwire[]{c.out}{b}
\outwire[]{d.out}{c}
\swire[0]{a/4}{c/1}{}{}
\swire[0]{b/1}{d/4}{}{}
\swire[0]{a/1}{d/1}{}{}
\swire[0]{b/4}{c/4}{}{}
\end{tikzpicture}
\end{subfigure}
\end{figure}

\begin{figure}[H]
\caption{Fan-fan annihilation}
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inetcell[]{a}{$f_i$}[5]
\inetcell[rotate = 180, below = 50 pt]{b}{\rotatebox[origin=c]{180}{$f_i$}}[5]
\inwire[]{a/1}{a}
\inwire[]{a/4}{d}
\outwire[]{b/1}{c}
\outwire[]{b/4}{b}
\cutWire{a.out}{b.out}{}{}
\end{tikzpicture}
\end{subfigure}
~
\begin{subfigure}[c]{0.05\textwidth}
\huge{→}
\end{subfigure}
~
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\wirestraight[]{a}{c}{b}{d}
\end{tikzpicture}
\end{subfigure}
\end{figure}

\begin{figure}[H]
\caption{Eraser-lambda commutation}
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inetcell[]{a}{$λ$}[5]
\inode[below = 40 pt]{b}{$⊗$}
\inwire[]{a/1}{a}
\inwire[]{a/4}{d}
\cutWire{a.out}{b.north}{}{}
\end{tikzpicture}
\end{subfigure}
~
\begin{subfigure}[c]{0.05\textwidth}
\huge{→}
\end{subfigure}
~
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inode[]{a}{$⊗$}
\inode[right = 20 pt]{b}{$⊗$}
\inwire[]{a}{a}
\inwire[]{b}{d}
\end{tikzpicture}
\end{subfigure}
\end{figure}

\begin{figure}[H]
\caption{Eraser-application commutation}
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inetcell[]{a}{$@$}[5]
\inode[below = 40 pt]{b}{$⊗$}
\inwire[]{a/1}{a}
\inwire[]{a/4}{d}
\cutWire{a.out}{b.north}{}{}
\end{tikzpicture}
\end{subfigure}
~
\begin{subfigure}[c]{0.05\textwidth}
\huge{→}
\end{subfigure}
~
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inode[]{a}{$⊗$}
\inode[right = 20 pt]{b}{$⊗$}
\inwire[]{a}{a}
\inwire[]{b}{d}
\end{tikzpicture}
\end{subfigure}
\end{figure}

\begin{figure}[H]
\caption{Eraser-fan commutation}
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inetcell[]{a}{$f_i$}[5]
\inode[below = 40 pt]{b}{$⊗$}
\inwire[]{a/1}{a}
\inwire[]{a/4}{d}
\cutWire{a.out}{b.north}{}{}
\end{tikzpicture}
\end{subfigure}
~
\begin{subfigure}[c]{0.05\textwidth}
\huge{→}
\end{subfigure}
~
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inode[]{a}{$⊗$}
\inode[right = 20 pt]{b}{$⊗$}
\inwire[]{a}{a}
\inwire[]{b}{d}
\end{tikzpicture}
\end{subfigure}
\end{figure}

\begin{figure}[H]
\caption{Eraser-eraser annihilation}
\begin{subfigure}[c]{0.1\textwidth}
\begin{tikzpicture}
\inode[]{a}{$⊗$}
\inode[below = 40 pt]{b}{$⊗$}
\vwire{a}{b}
\end{tikzpicture}
\end{subfigure}
~
\begin{subfigure}[c]{0.05\textwidth}
\huge{→}
\end{subfigure}
~
\begin{subfigure}[c]{0.1\textwidth}
\end{subfigure}
\end{figure}

\floatstyle{boxed}
\restylefloat{figure}

### Argument for correctness

1. Define the level of a subterm
    1. level a a = 0
    1. level lam x . a b = level a b
    1. level a b c = level a c or level b c as appropriate
    1. level !a b = 1 + level a b
    1. level $\bar{!}a$ b = -1 + level a b
1. The level of a subterm is constant through beta reduction
    1. lam x . t -> lam x . t (trivial)
    1. x -> x (trivial)
    1. !x -> !x (trivial)
    1. ! $\bar{!}$ x -> x (trivial) (defined-ness guaranteed by well-bracketed property)
    1. (lam x . a) b -> a [ x := b ]
        1. If t was in a - trivial
        1. If t was in b - level a x = 0 by well-bracketed property, so level b t = level (a [ x := b ]) t
1. Map this level to nodes in the interaction net translation
    1. Think concentric boxes with natural number levels
1. Level of node does not change during reduction
    1. Beta reduction only connects nodes on same level
1. Levels can be chosen from contraction nodes of EAL type derivation
    1. Contraction nodes do not change level during proof-net reduction
    1. Also do not change level during abstract algorithm reduction
    1. If fans match label, must have originated from that level
    1. Algorithm is correct with EAL term subset since label indicates level of fan and level does not change according to EAL rules
    1. No loops in reduction of EAL-typable terms that would render labels underspecified

(needs pretty pictures)

## Evaluator cost model

Currently tracked:

- Memory allocations
- Sequential rewrite steps
- Parallel rewrite steps
- Maximum graph size
- Final graph size

In the future we may want to track more granular memory operations (reads/writes in addition to allocations) and computations associated with rewrite rules (all negligible-cost with interaction combinators, but not with e.g. integer arithmetic).

Machine backends are expected to provide a discrete cost model which can be utilised by the optimiser.

## Future optimisation strategies

Juvix does not yet implement these, but the compiler architecture has kept their possibility in mind.

### Spacial memory contiguity

Random access O(1) model is imperfect; sequential reads are faster. Ensure correspondence between graphical locality and spacial locality in memory, read nodes in blocks.

### Speculative execution

- "Strict" optimal reduction strategies
- Evaluate based on predicting future input (feasible?)

### Stochastic superoptimisation

- Utilise sparse sampling (probably Markov-chain Monte Carlo) to search the configuration space of semantically equivalent programs & select the fastest.
- Probably useful at the level of choosing machine implementations of particular rewrite rules.
- See Stochastic Superoptimisation [@stochastic-superoptimization]
- Will need a lot of clever tricks to avoid getting stuck in local minima (that paper details several).
- See also STOKE [@stoke]

### "Superoptimal" reduction strategies

- Specifically those with the possibility of asymptotically-better performance than Levy's optimal reduction.
- As far as I can tell, the only candidates here are forms of memoisation which attempt to detect syntactically identical structures during the reduction process which can then be linked and evaluated only once.
- [Hash consing](https://en.wikipedia.org/wiki/Hash_consing) may have the most prior research.
- Concerns about space-time trade-offs (may already be concerns).
