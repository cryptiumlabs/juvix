Machine defines:

- Primitive types
- Primitive functions & costs
- Primitive typing relation
- Bespoke encoding path
- (optionally) Interaction net interpreter
- (optionally) Optimisation passes

## LLVM

Target LLVM IR, with parallel (thread?) support.

Full backend.

Experiment with "unrolling" the basic interaction net evaluator case switch by some degree $k$, such that intermediate allocations can be optimised away at compile-time - code size will be $c ^ k$ with $c$ the number of branches, but that's still fine for a few levels of unrolling.

This transformation is trivially semantics-preserving in the single-thread case and no additional bookkeeping is necessary. In the multi-thread case, if two threads start reduction less than $k$ hops from each other (hop = wire between nodes), they may reduce overlapping primary pairs, which could be problematic. We could either attempt to eliminate this possibility at compile time, which will require a fair bit of knowledge about where parallel reduction will occur (but perhaps possible, especially with explicit annotations), or reduce optimistically in parallel, insert synchronisation points where necessary, and revert conflicting changes in a semantics-preserving way - an approach which is more complicated to reason about, but doesn't require compile-time knowledge of "distance" between threads rewriting the graph in parallel.

## Michelson

Target Michelson.

Bespoke compilation path only.

- Stack tracking
- Calling conventions
- Clear stack when variable won't be used again

## WASM

Target WASM. Parallelism?

## EVM

Target EVM v1.x. Maybe pointless and should focus on eWASM instead.

## Berkeley Packet Filter

Target [BPF](https://en.wikipedia.org/wiki/Berkeley_Packet_Filter) possibly, Solana uses this.

## GPUs (CUDA / OpenCL)

Excellent way to demonstrate parallelism.

Full backend.

Consider fusing with LLVM.

## FPGA

Parallelism + versatility, maybe there are large efficiency gains possible, different memory costs.

Full backend.

## Algebraic intermediate representation (STARKs)

Ideally a developer-facing language would operate at a higher level, automatically determining the necessary registers, length of execution trace, transition function & transition constraints. I think this should be possible to do automatically pretty efficiently - possibly in some cases custom constraints could be defined & proved to be equivalent to correct execution of the transition function (e.g., for a layer l_n in a trace, l_n = f(l_n-1) <=> c l_n l_n-1 where c is the constraint relation).

I am not sure if an interaction net transition function can be efficiently encoded in a STARK. I think the transition function itself is less likely to be a problem than the memory accesses (which will require a Merkle tree & proofs for all reads, probably). The concrete numbers here (especially prover time & proof size) may be prohibitively high. Apparently 1-layer recursion in STARKs is possible; I do not know the details. DEEP-FRI should also help.

At minimum, even with "function-to-constraints" compilation, a custom library will be necessary to import STARK-friendly hash functions, signature schemes, etc.

- Construct registers to hold all values
- Use public / private type distinctions for register separation
- ADTs must be completely erased by runtime
- Require primitive type (or tuple, or encodable/decodable ADT) input, output
- Specific primitive types supported by STARKs (field-dependent)
- Unroll loops completely, must have finite length

Questions:
- Can QTT provide sufficient precision to allow all register allocation to happen statically?
- If we inline everything, can higher-order functions be erased (want to avoid interaction net evaluation, since that requires dynamic memory allocation)?
- Transforms to reuse registers over time ~ may be prior literature or forms, e.g. SSA
- Figure out rough numbers for size, proof time scaling vs. register count

## Rank-1 constraint systems (SNARKs)

Also possible, albeit likely less efficient encoding-wise (for repeated computation).
